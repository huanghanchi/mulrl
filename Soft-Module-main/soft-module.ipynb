{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-24 23:42:58,096 MainThread INFO: Experiment Name:MT10_Fixed_Modular_Shallow\n",
      "2021-01-24 23:42:58,099 MainThread INFO: {\n",
      "  \"env_name\": \"mt10\",\n",
      "  \"env\": {\n",
      "    \"reward_scale\": 1,\n",
      "    \"obs_norm\": false\n",
      "  },\n",
      "  \"meta_env\": {\n",
      "    \"obs_type\": \"with_goal\"\n",
      "  },\n",
      "  \"replay_buffer\": {\n",
      "    \"size\": 1000000.0\n",
      "  },\n",
      "  \"net\": {\n",
      "    \"hidden_shapes\": [\n",
      "      400,\n",
      "      400\n",
      "    ],\n",
      "    \"em_hidden_shapes\": [\n",
      "      400\n",
      "    ],\n",
      "    \"num_layers\": 2,\n",
      "    \"num_modules\": 2,\n",
      "    \"module_hidden\": 256,\n",
      "    \"num_gating_layers\": 2,\n",
      "    \"gating_hidden\": 256,\n",
      "    \"add_bn\": false,\n",
      "    \"pre_softmax\": false\n",
      "  },\n",
      "  \"general_setting\": {\n",
      "    \"discount\": 0.99,\n",
      "    \"pretrain_epochs\": 20,\n",
      "    \"num_epochs\": 7500,\n",
      "    \"epoch_frames\": 200,\n",
      "    \"max_episode_frames\": 200,\n",
      "    \"batch_size\": 1280,\n",
      "    \"min_pool\": 10000,\n",
      "    \"target_hard_update_period\": 1000,\n",
      "    \"use_soft_update\": true,\n",
      "    \"tau\": 0.005,\n",
      "    \"opt_times\": 200,\n",
      "    \"eval_episodes\": 3\n",
      "  },\n",
      "  \"sac\": {\n",
      "    \"plr\": 0.0003,\n",
      "    \"qlr\": 0.0003,\n",
      "    \"reparameterization\": true,\n",
      "    \"automatic_entropy_tuning\": true,\n",
      "    \"temp_reweight\": true,\n",
      "    \"policy_std_reg_weight\": 0,\n",
      "    \"policy_mean_reg_weight\": 0\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Could not seed environment <MTEnv instance>\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "relu() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-09a2d47aa32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mexample_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_task_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m pf = policies.ModularGuassianGatedCascadeCondContPolicy(\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mem_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/metaworld-master/Soft-Module-main/torchrl/networks/nets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_shape, base_type, em_input_shape, input_shape, em_hidden_shapes, hidden_shapes, num_layers, num_modules, module_hidden, gating_hidden, num_gating_layers, add_bn, pre_softmax, cond_ob, module_hidden_init_func, last_init_func, activation_func, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         self.base = base_type( \n\u001b[0m\u001b[1;32m     97\u001b[0m                         \u001b[0mlast_activation_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull_activation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/metaworld-master/Soft-Module-main/torchrl/networks/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, hidden_shapes, activation_func, init_func, add_ln, last_activation_func)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ln\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: relu() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import metaworld\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchrl.utils import get_args\n",
    "from torchrl.utils import get_params\n",
    "from torchrl.env import get_env\n",
    "\n",
    "\n",
    "from torchrl.utils import Logger\n",
    "\n",
    "class parser:\n",
    "    def __init__(self):\n",
    "        self.config='meta_config/mt10/modular_2_2_2_256_reweight.json'\n",
    "        self.id='MT10_Fixed_Modular_Shallow'\n",
    "        self.worker_nums=10\n",
    "        self.eval_worker_nums=10\n",
    "        self.seed=20\n",
    "        self.log_dir='./log/MT10'\n",
    "        self.pf_snap=r'/root/metaworld-master/softmodule_log_5/MT10/MT10_Fixed_Modular_Shallow/mt10/20/model/model_pf_best.pth'\n",
    "        self.pf1_snap=None\n",
    "        self.pf2_snap=None\n",
    "        self.qf1_snap=r'/root/metaworld-master/softmodule_log_5/MT10/MT10_Fixed_Modular_Shallow/mt10/20/model/model_qf1_best.pth'\n",
    "        self.qf2_snap=r'/root/metaworld-master/softmodule_log_5/MT10/MT10_Fixed_Modular_Shallow/mt10/20/model/model_qf2_best.pth'\n",
    "        \n",
    "args=parser()\n",
    "params = get_params(args.config)\n",
    "\n",
    "import torchrl.policies as policies\n",
    "import torchrl.networks as networks\n",
    "from torchrl.algo import SAC\n",
    "from torchrl.algo import TwinSAC\n",
    "from torchrl.algo import TwinSACQ\n",
    "from torchrl.algo import MTSAC\n",
    "from torchrl.collector.para import ParallelCollector\n",
    "from torchrl.collector.para import AsyncParallelCollector\n",
    "from torchrl.collector.para.mt import SingleTaskParallelCollectorBase\n",
    "from torchrl.collector.para.async_mt import AsyncSingleTaskParallelCollector\n",
    "from torchrl.collector.para.async_mt import AsyncMultiTaskParallelCollectorUniform\n",
    "\n",
    "from torchrl.replay_buffers.shared import SharedBaseReplayBuffer\n",
    "from torchrl.replay_buffers.shared import AsyncSharedReplayBuffer\n",
    "import gym\n",
    "\n",
    "from metaworld_utils.meta_env import get_meta_env\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "env, cls_dicts, cls_args = get_meta_env( params['env_name'], params['env'], params['meta_env'])\n",
    "\n",
    "env.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "buffer_param = params['replay_buffer']\n",
    "\n",
    "experiment_name = os.path.split( os.path.splitext( args.config )[0] )[-1] if args.id is None \\\n",
    "    else args.id\n",
    "logger = Logger( experiment_name , params['env_name'], args.seed, params, args.log_dir )\n",
    "\n",
    "params['general_setting']['env'] = env\n",
    "params['general_setting']['logger'] = logger\n",
    "params['general_setting']['device'] = device\n",
    "\n",
    "params['net']['base_type']=networks.MLPBase\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "from torchrl.networks.init import normal_init\n",
    "\n",
    "example_ob = env.reset()\n",
    "example_embedding = env.active_task_one_hot\n",
    "\n",
    "pf = policies.ModularGuassianGatedCascadeCondContPolicy(\n",
    "    input_shape=env.observation_space.shape[0],\n",
    "    em_input_shape=np.prod(example_embedding.shape),\n",
    "    output_shape=2 * env.action_space.shape[0],\n",
    "    **params['net'])\n",
    "\n",
    "if args.pf_snap is not None:\n",
    "    pf.load_state_dict(torch.load('/root/metaworld-master/softmodule_log_5/MT10/MT10_Fixed_Modular_Shallow/mt10/20/model/model_pf_best.pth', map_location='cpu'))\n",
    "\n",
    "qf1 = networks.FlattenModularGatedCascadeCondNet(\n",
    "    input_shape=env.observation_space.shape[0] + env.action_space.shape[0],\n",
    "    em_input_shape=np.prod(example_embedding.shape),\n",
    "    output_shape=1,\n",
    "    **params['net'])\n",
    "qf2 = networks.FlattenModularGatedCascadeCondNet( \n",
    "    input_shape=env.observation_space.shape[0] + env.action_space.shape[0],\n",
    "    em_input_shape=np.prod(example_embedding.shape),\n",
    "    output_shape=1,\n",
    "    **params['net'])\n",
    "\n",
    "if args.qf1_snap is not None:\n",
    "    qf1.load_state_dict(torch.load(args.qf2_snap, map_location='cpu'))\n",
    "if args.qf2_snap is not None:\n",
    "    qf2.load_state_dict(torch.load(args.qf2_snap, map_location='cpu'))\n",
    "\n",
    "example_dict = { \n",
    "    \"obs\": example_ob,\n",
    "    \"next_obs\": example_ob,\n",
    "    \"acts\": env.action_space.sample(),\n",
    "    \"rewards\": [0],\n",
    "    \"terminals\": [False],\n",
    "    \"task_idxs\": [0],\n",
    "    \"embedding_inputs\": example_embedding\n",
    "}\n",
    "\n",
    "replay_buffer = AsyncSharedReplayBuffer(int(buffer_param['size']),\n",
    "        args.worker_nums\n",
    ")\n",
    "replay_buffer.build_by_example(example_dict)\n",
    "\n",
    "params['general_setting']['replay_buffer'] = replay_buffer\n",
    "\n",
    "epochs = params['general_setting']['pretrain_epochs'] + \\\n",
    "    params['general_setting']['num_epochs']\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "params['general_setting']['collector'] = AsyncMultiTaskParallelCollectorUniform(\n",
    "    env=env, pf=pf, replay_buffer=replay_buffer,\n",
    "    env_cls = cls_dicts, env_args = [params[\"env\"], cls_args, params[\"meta_env\"]],\n",
    "    device=device,\n",
    "    reset_idx=True,\n",
    "    epoch_frames=params['general_setting']['epoch_frames'],\n",
    "    max_episode_frames=params['general_setting']['max_episode_frames'],\n",
    "    eval_episodes = params['general_setting']['eval_episodes'],\n",
    "    worker_nums=args.worker_nums, eval_worker_nums=args.eval_worker_nums,\n",
    "    train_epochs = epochs, eval_epochs= params['general_setting']['num_epochs']\n",
    ")\n",
    "params['general_setting']['batch_size'] = int(params['general_setting']['batch_size'])\n",
    "params['general_setting']['save_dir'] = osp.join(logger.work_dir,\"model\")\n",
    "agent = MTSAC(\n",
    "    pf = pf,\n",
    "    qf1 = qf1,\n",
    "    qf2 = qf2,\n",
    "    task_nums=env.num_tasks,\n",
    "    **params['sac'],\n",
    "    **params['general_setting']\n",
    ")\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
